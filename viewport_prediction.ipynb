{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#360 degree video content based viewport prediction\n",
    "LSTM-ekf hybrd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_ROOT = Path(\"/kaggle/input/d-sav360\")\n",
    "    HEAD_DATA_DIR = DATA_ROOT / \"head\"\n",
    "    DEV_MODE = True\n",
    "    DEV_VIDEO_ID = \"0001\"\n",
    "    PREDICTION_HORIZON_SEC = 2.5\n",
    "    INPUT_HISTORY_SEC = 2.0\n",
    "    SAMPLE_RATE_HZ = 90\n",
    "    PREDICTION_STEPS = int(PREDICTION_HORIZON_SEC * SAMPLE_RATE_HZ)\n",
    "    INPUT_STEPS = int(INPUT_HISTORY_SEC * SAMPLE_RATE_HZ)\n",
    "    LSTM_HIDDEN_SIZE = 128\n",
    "    LSTM_NUM_LAYERS = 2\n",
    "    LSTM_DROPOUT = 0.2\n",
    "    EKF_PROCESS_NOISE = 0.01\n",
    "    EKF_MEASUREMENT_NOISE = 0.001\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 1e-3\n",
    "    NUM_EPOCHS = 50\n",
    "    EARLY_STOPPING_PATIENCE = 10\n",
    "    EVAL_HORIZONS = [0.5, 1.0, 1.5, 2.0, 2.5]\n",
    "    TRAIN_RATIO = 0.7\n",
    "    VAL_RATIO = 0.15\n",
    "\n",
    "config = Config()\n",
    "print(f\"Prediction: {config.INPUT_STEPS} steps -> {config.PREDICTION_STEPS} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spherical Geometry Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalUtils:\n",
    "    @staticmethod\n",
    "    def uv_to_unit_vector(u, v):\n",
    "        theta = u * 2 * np.pi\n",
    "        phi = (v - 0.5) * np.pi\n",
    "        x = np.cos(phi) * np.cos(theta)\n",
    "        y = np.cos(phi) * np.sin(theta)\n",
    "        z = np.sin(phi)\n",
    "        return np.stack([x, y, z], axis=-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def unit_vector_to_uv(p):\n",
    "        x, y, z = p[..., 0], p[..., 1], p[..., 2]\n",
    "        theta = np.arctan2(y, x)\n",
    "        theta = np.where(theta < 0, theta + 2 * np.pi, theta)\n",
    "        phi = np.arcsin(np.clip(z, -1, 1))\n",
    "        return theta / (2 * np.pi), phi / np.pi + 0.5\n",
    "    \n",
    "    @staticmethod\n",
    "    def tangent_velocity(p_t, p_next):\n",
    "        dot = np.sum(p_t * p_next, axis=-1, keepdims=True)\n",
    "        dot = np.clip(dot, -1.0, 1.0)\n",
    "        tangent = p_next - dot * p_t\n",
    "        tangent_norm = np.linalg.norm(tangent, axis=-1, keepdims=True) + 1e-8\n",
    "        angle = np.arccos(dot)\n",
    "        return (tangent / tangent_norm) * angle\n",
    "    \n",
    "    @staticmethod\n",
    "    def exp_map(p, v):\n",
    "        v_norm = np.linalg.norm(v, axis=-1, keepdims=True) + 1e-8\n",
    "        result = np.cos(v_norm) * p + np.sin(v_norm) * (v / v_norm)\n",
    "        return result / (np.linalg.norm(result, axis=-1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(p):\n",
    "        return p / (np.linalg.norm(p, axis=-1, keepdims=True) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalUtilsTorch:\n",
    "    @staticmethod\n",
    "    def normalize(p):\n",
    "        return p / (torch.norm(p, dim=-1, keepdim=True) + 1e-8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def exp_map(p, v):\n",
    "        v_norm = torch.norm(v, dim=-1, keepdim=True) + 1e-8\n",
    "        result = torch.cos(v_norm) * p + torch.sin(v_norm) * (v / v_norm)\n",
    "        return SphericalUtilsTorch.normalize(result)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_loss(p_pred, p_target):\n",
    "        return 1.0 - torch.sum(p_pred * p_target, dim=-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def angular_error_degrees(p_pred, p_target):\n",
    "        dot = torch.clamp(torch.sum(p_pred * p_target, dim=-1), -1.0, 1.0)\n",
    "        return torch.acos(dot) * (180.0 / np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_head_tracking_data(video_id, data_dir):\n",
    "    file_path = data_dir / f\"head_video_{video_id}.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    unit_vecs = SphericalUtils.uv_to_unit_vector(df['u'].values, df['v'].values)\n",
    "    df['px'], df['py'], df['pz'] = unit_vecs[:, 0], unit_vecs[:, 1], unit_vecs[:, 2]\n",
    "    return df\n",
    "\n",
    "def split_by_participant(participant_ids, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    ids = np.array(participant_ids)\n",
    "    np.random.shuffle(ids)\n",
    "    n = len(ids)\n",
    "    n_train, n_val = int(n * train_ratio), int(n * val_ratio)\n",
    "    return ids[:n_train].tolist(), ids[n_train:n_train+n_val].tolist(), ids[n_train+n_val:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewportDataset(Dataset):\n",
    "    def __init__(self, df, participant_ids, input_steps, prediction_steps, eval_horizons_steps):\n",
    "        self.input_steps = input_steps\n",
    "        self.prediction_steps = prediction_steps\n",
    "        self.eval_horizons_steps = eval_horizons_steps\n",
    "        self.sequences = []\n",
    "        \n",
    "        df_filtered = df[df['id'].isin(participant_ids)].copy()\n",
    "        for pid in participant_ids:\n",
    "            pdf = df_filtered[df_filtered['id'] == pid].sort_values('t')\n",
    "            if len(pdf) < input_steps + prediction_steps:\n",
    "                continue\n",
    "            positions = pdf[['px', 'py', 'pz']].values\n",
    "            velocities = np.zeros_like(positions)\n",
    "            velocities[:-1] = SphericalUtils.tangent_velocity(positions[:-1], positions[1:])\n",
    "            velocities[-1] = velocities[-2]\n",
    "            \n",
    "            total_len = input_steps + prediction_steps\n",
    "            for i in range(len(positions) - total_len + 1):\n",
    "                self.sequences.append({\n",
    "                    'positions': positions[i:i+total_len],\n",
    "                    'velocities': velocities[i:i+total_len],\n",
    "                    'pid': pid\n",
    "                })\n",
    "        print(f\"Created {len(self.sequences)} sequences\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        targets = [seq['positions'][self.input_steps - 1 + h] for h in self.eval_horizons_steps]\n",
    "        return {\n",
    "            'input_positions': torch.FloatTensor(seq['positions'][:self.input_steps]),\n",
    "            'input_velocities': torch.FloatTensor(seq['velocities'][:self.input_steps]),\n",
    "            'targets': torch.FloatTensor(np.array(targets))\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extended Kalman Filter (Frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalEKF:\n",
    "    def __init__(self, process_noise=0.01, measurement_noise=0.001, dt=1.0/90):\n",
    "        self.dt = dt\n",
    "        self.Q = np.eye(6) * process_noise\n",
    "        self.Q[:3, :3] *= 0.1\n",
    "        self.R = np.eye(3) * measurement_noise\n",
    "        self.F = np.eye(6)\n",
    "        self.F[:3, 3:] = np.eye(3) * dt\n",
    "        self.H = np.zeros((3, 6))\n",
    "        self.H[:3, :3] = np.eye(3)\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x = np.zeros(6)\n",
    "        self.x[2] = 1.0\n",
    "        self.P = np.eye(6) * 0.1\n",
    "        self.initialized = False\n",
    "    \n",
    "    def predict_trajectory(self, steps):\n",
    "        trajectory = np.zeros((steps, 3))\n",
    "        x_pred = self.x.copy()\n",
    "        for i in range(steps):\n",
    "            x_pred = self.F @ x_pred\n",
    "            x_pred[:3] = SphericalUtils.normalize(x_pred[:3])\n",
    "            trajectory[i] = x_pred[:3]\n",
    "        return trajectory\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        if not self.initialized:\n",
    "            self.x[:3] = measurement\n",
    "            self.initialized = True\n",
    "            return measurement, 0.0\n",
    "        \n",
    "        x_pred = self.F @ self.x\n",
    "        x_pred[:3] = SphericalUtils.normalize(x_pred[:3])\n",
    "        P_pred = self.F @ self.P @ self.F.T + self.Q\n",
    "        y = measurement - self.H @ x_pred\n",
    "        innovation_mag = np.linalg.norm(y)\n",
    "        S = self.H @ P_pred @ self.H.T + self.R\n",
    "        K = P_pred @ self.H.T @ np.linalg.inv(S)\n",
    "        self.x = x_pred + K @ y\n",
    "        self.x[:3] = SphericalUtils.normalize(self.x[:3])\n",
    "        self.P = (np.eye(6) - K @ self.H) @ P_pred\n",
    "        return self.x[:3], innovation_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchEKF:\n",
    "    def __init__(self, config):\n",
    "        self.ekf = SphericalEKF(config.EKF_PROCESS_NOISE, config.EKF_MEASUREMENT_NOISE)\n",
    "    \n",
    "    def process_batch(self, input_positions, eval_horizons_steps):\n",
    "        batch_size, seq_len = input_positions.shape[:2]\n",
    "        positions_np = input_positions.cpu().numpy()\n",
    "        ekf_preds = np.zeros((batch_size, len(eval_horizons_steps), 3))\n",
    "        innovations = np.zeros((batch_size, seq_len))\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            self.ekf.reset()\n",
    "            for t in range(seq_len):\n",
    "                _, innov = self.ekf.update(positions_np[b, t])\n",
    "                innovations[b, t] = innov\n",
    "            traj = self.ekf.predict_trajectory(max(eval_horizons_steps))\n",
    "            for i, h in enumerate(eval_horizons_steps):\n",
    "                ekf_preds[b, i] = traj[h - 1]\n",
    "        \n",
    "        return torch.FloatTensor(ekf_preds).to(input_positions.device), torch.FloatTensor(innovations).to(input_positions.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LSTM Model with Gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=6, hidden_size=128, num_layers=2, dropout=0.2, num_horizons=5):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, batch_first=True, \n",
    "                           dropout=dropout if num_layers > 1 else 0)\n",
    "        self.prediction_heads = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(hidden_size, hidden_size//2), nn.ReLU(), \n",
    "                         nn.Dropout(dropout), nn.Linear(hidden_size//2, 3))\n",
    "            for _ in range(num_horizons)\n",
    "        ])\n",
    "        self.gate_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size + 1, hidden_size//4), nn.ReLU(),\n",
    "            nn.Linear(hidden_size//4, num_horizons), nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_positions, input_velocities, innovation_magnitude):\n",
    "        lstm_input = torch.cat([input_positions, input_velocities], dim=-1)\n",
    "        lstm_out, _ = self.lstm(lstm_input)\n",
    "        hidden = lstm_out[:, -1, :]\n",
    "        corrections = torch.stack([head(hidden) for head in self.prediction_heads], dim=1)\n",
    "        gate_input = torch.cat([hidden, innovation_magnitude.mean(dim=-1, keepdim=True)], dim=-1)\n",
    "        gates = self.gate_head(gate_input)\n",
    "        return corrections, gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanLSTMHybrid(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.eval_horizons_steps = [int(h * config.SAMPLE_RATE_HZ) for h in config.EVAL_HORIZONS]\n",
    "        self.batch_ekf = BatchEKF(config)\n",
    "        self.lstm = SphericalLSTM(6, config.LSTM_HIDDEN_SIZE, config.LSTM_NUM_LAYERS,\n",
    "                                  config.LSTM_DROPOUT, len(config.EVAL_HORIZONS))\n",
    "    \n",
    "    def forward(self, input_positions, input_velocities):\n",
    "        ekf_preds, innovations = self.batch_ekf.process_batch(input_positions, self.eval_horizons_steps)\n",
    "        corrections, gates = self.lstm(input_positions, input_velocities, innovations)\n",
    "        gated_corrections = gates.unsqueeze(-1) * corrections\n",
    "        predictions = SphericalUtilsTorch.exp_map(ekf_preds, gated_corrections)\n",
    "        return predictions, {'ekf_predictions': ekf_preds, 'gates': gates, 'innovations': innovations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Loss & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHorizonLoss(nn.Module):\n",
    "    def __init__(self, horizon_weights=None):\n",
    "        super().__init__()\n",
    "        self.horizon_weights = horizon_weights\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        cosine_losses = SphericalUtilsTorch.cosine_loss(predictions, targets)\n",
    "        if self.horizon_weights:\n",
    "            weights = torch.tensor(self.horizon_weights, device=predictions.device)\n",
    "            loss = (cosine_losses * weights.unsqueeze(0)).mean()\n",
    "        else:\n",
    "            loss = cosine_losses.mean()\n",
    "        return loss, {f'loss_h{i}': cosine_losses[:, i].mean().item() for i in range(cosine_losses.shape[1])}\n",
    "\n",
    "def evaluate_model(model, dataloader, config, device):\n",
    "    model.eval()\n",
    "    all_errors = {h: [] for h in config.EVAL_HORIZONS}\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            preds, _ = model(batch['input_positions'].to(device), batch['input_velocities'].to(device))\n",
    "            targets = batch['targets'].to(device)\n",
    "            for i, h in enumerate(config.EVAL_HORIZONS):\n",
    "                errors = SphericalUtilsTorch.angular_error_degrees(preds[:, i], targets[:, i])\n",
    "                all_errors[h].extend(errors.cpu().numpy().tolist())\n",
    "    return {f'MAE_{h}s': np.mean(all_errors[h]) for h in config.EVAL_HORIZONS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, num_batches = 0.0, 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        preds, _ = model(batch['input_positions'].to(device), batch['input_velocities'].to(device))\n",
    "        loss, _ = criterion(preds, batch['targets'].to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    return {'train_loss': total_loss / num_batches}\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, num_batches = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            preds, _ = model(batch['input_positions'].to(device), batch['input_velocities'].to(device))\n",
    "            loss, _ = criterion(preds, batch['targets'].to(device))\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    return {'val_loss': total_loss / num_batches}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, config, device):\n",
    "    model = model.to(device)\n",
    "    criterion = MultiHorizonLoss([0.5, 0.7, 0.85, 1.0, 1.0])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    best_val_loss, patience_counter, best_state = float('inf'), 0, None\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        train_metrics = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_metrics = validate(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_metrics['val_loss'])\n",
    "        \n",
    "        history['train_loss'].append(train_metrics['train_loss'])\n",
    "        history['val_loss'].append(val_metrics['val_loss'])\n",
    "        \n",
    "        if val_metrics['val_loss'] < best_val_loss:\n",
    "            best_val_loss = val_metrics['val_loss']\n",
    "            patience_counter = 0\n",
    "            best_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}: train={train_metrics['train_loss']:.4f}, val={val_metrics['val_loss']:.4f}\")\n",
    "        \n",
    "        if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    ax.plot(history['train_loss'], label='Train')\n",
    "    ax.plot(history['val_loss'], label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_vs_horizon(metrics, config):\n",
    "    horizons = config.EVAL_HORIZONS\n",
    "    errors = [metrics[f'MAE_{h}s'] for h in horizons]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(horizons, errors, 'o-', lw=2, ms=8)\n",
    "    plt.xlabel('Horizon (s)')\n",
    "    plt.ylabel('MAE (degrees)')\n",
    "    plt.title('Angular Error vs Prediction Horizon')\n",
    "    plt.grid(True)\n",
    "    for h, e in zip(horizons, errors):\n",
    "        plt.annotate(f'{e:.1f}°', (h, e), textcoords='offset points', xytext=(0, 10), ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (single video for development)\n",
    "print(\"Loading data...\")\n",
    "df = load_head_tracking_data(config.DEV_VIDEO_ID, config.HEAD_DATA_DIR)\n",
    "print(f\"Loaded {len(df)} samples from video {config.DEV_VIDEO_ID}\")\n",
    "\n",
    "# Split by participant\n",
    "participant_ids = sorted(df['id'].unique().tolist())\n",
    "train_ids, val_ids, test_ids = split_by_participant(participant_ids)\n",
    "print(f\"Participants - Train: {len(train_ids)}, Val: {len(val_ids)}, Test: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "eval_horizons_steps = [int(h * config.SAMPLE_RATE_HZ) for h in config.EVAL_HORIZONS]\n",
    "\n",
    "train_dataset = ViewportDataset(df, train_ids, config.INPUT_STEPS, config.PREDICTION_STEPS, eval_horizons_steps)\n",
    "val_dataset = ViewportDataset(df, val_ids, config.INPUT_STEPS, config.PREDICTION_STEPS, eval_horizons_steps)\n",
    "test_dataset = ViewportDataset(df, test_ids, config.INPUT_STEPS, config.PREDICTION_STEPS, eval_horizons_steps)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train model\n",
    "model = KalmanLSTMHybrid(config)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "model, history = train_model(model, train_loader, val_loader, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "plot_training_history(history)\n",
    "\n",
    "test_metrics = evaluate_model(model, test_loader, config, device)\n",
    "print(\"\\nTest Results:\")\n",
    "for h in config.EVAL_HORIZONS:\n",
    "    print(f\"  MAE @ {h}s: {test_metrics[f'MAE_{h}s']:.2f}°\")\n",
    "\n",
    "plot_error_vs_horizon(test_metrics, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
